# 100 Days Of Code - Log


### Day 0: January 2nd 2017
##### (KINDA-When I started writing this it was)

**Today's Progress**: Decided to commit to #100daysofcode, and I'm going to Use Python. Although I might decide to do some freecodecamp projects here and there as I've been wanting to learn Web Development.

**Thoughts:** Well right now it is technically 1/3/2017, 12:05AM at night and I haven't slept yet so It's still technically Day 0. I plan to do my coding tomorrow around 2-6pm. I have an idea of what I want to start working on. Since I've been learning Data Science and how to use things like Selenium, and Beautifulsoup; I want to build a project that checks stock market info for tech companies like facebook, google, etc and puts it into a DataFrame(since I'm getting into pandas at the moment). I just got the idea that I could also make it into an alexa app and have alexa get me the stock market values for a certain company I ask for... We'll see :D. 

####NOTE TO SELF: During these 100 days would be a good time to work on the what should I wear and other skillets xD

**Link to work:** [Me publicly commiting to #100daysofcode](https://twitter.com/Shablam6/status/816144867432734720)

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Starting my <a href="https://twitter.com/hashtag/100DaysOfCode?src=hash">#100DaysOfCode</a> tomorrow 1/3/2017! I will be using Python for the 100 days, but I might also add in some <a href="https://twitter.com/FreeCodeCamp">@FreeCodeCamp</a> projects!</p>&mdash; Jay (@Shablam6) <a href="https://twitter.com/Shablam6/status/816144867432734720">January 3, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

### Day 1: January 3rd 2017

**Today's Progress**: Created a scraper that lets takes the input of a user, but it has to be the stock market abbreviation/name of a company, and scrapes yahoo's financial page for that company, and returns the results in a pandas DataFrame. :). I was going to make it so that it would ask you if you wanted to scrape again but I ran into a lot of trouble doing that for some reason, and it took me way too long to work on that when I wasn't even finished with getting the data into a DataFrame, so I dropped that, and decided to finish the basic functionality of the code. I'm planning to add on to the code as I go along and add more functionality to it. Wish me luck!

**Thoughts**: I have a seperate log that I put in 100-days-of-code/Projects/Day(X) that I write to locally as I run into problems and things. But I will also write my thoughts to this log... I ran into a lot of problems with what I wanted to do today, and kept thinking that I was done, but then ran into another issue. I spent way more than an hour on what I did, and I'm happy I stuck with it and finished the first day :D. They say the hardest part of doing things is taking that first step and getting starting/ commiting to something. I hope that I'll be able to stick with this! Also, it's 12:41am 1/4/2017 right now but as the rules stated, it still counts for the other day because I haven't gone to sleep yet, and I was actually doing the majority of my coding before 12am(it took me a while to finish this project :X). Anyway I can't wait to have some more fun tomorrow! :D

**Link(s) to work**: [Scraper To DataFrame](https://gist.github.com/JayBk/ca177a944edc3a89704d04aa031795c3)

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Finished Day 1 of <a href="https://twitter.com/hashtag/100DaysOfCode?src=hash">#100DaysOfCode</a> :D Glad I stuck with my commitment for atleast one day! Not much but I worked hard!<a href="https://t.co/DSXZXwZoqz">https://t.co/DSXZXwZoqz</a> <a href="https://t.co/IbAuuhqfKa">pic.twitter.com/IbAuuhqfKa</a></p>&mdash; Jay (@Shablam6) <a href="https://twitter.com/Shablam6/status/816522316070973440">January 4, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

### Day 2: January 4th 2017

**Today's Progress**: Not much today. Just a program that gets the top 10 new posts from any subreddit using reddits api and relays it back to you.

**Thoughts**: I first wanted to do something using selenium; I wanted to get the last game score for any hockey team that the user wanted.. It wasn't going well at all, so about a half hour in, I scratched it and then decided to do what I did. I plan on making one or two more scraper like programs(note to self: twitter), and put it all into a GUI with buttons for each of them using PyQT. I was going to stop after I scratched the selenium program, but forced myself to think and keep coding. I'm glad I did, and I'm glad I've at least gotten to Day 2! :D

**Link(s) to work**: [Get Any Reddit Subreddit 10 Newest Posts](https://gist.github.com/JayBk/02163ac2b69fd80c9a5b615c4fa884d0)

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Finished Day 2 of <a href="https://twitter.com/hashtag/100DaysOfCode?src=hash">#100DaysOfCode</a> after 12am again xD Not much today, but I have more planned in the coming days :) <a href="https://t.co/emSuuLvoca">https://t.co/emSuuLvoca</a></p>&mdash; Jay (@Shablam6) <a href="https://twitter.com/Shablam6/status/816907688626049024">January 5, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
